from fastapi import FastAPI, UploadFile, File, HTTPException
from .pdf_utils import pdf_to_text
from .embed_utils import upsert_text
from .rag_utils import answer, stream_answer

from sse_starlette.sse import EventSourceResponse

app = FastAPI()




@app.post("/ingest")
async def ingest(file: UploadFile = File(...)):
    if file.content_type != "application/pdf":
        raise HTTPException(status_code=415, detail="Only PDF files are supported.")
    pdf_bytes = await file.read()
    text = pdf_to_text(pdf_bytes)
    doc_id = file.filename
    n_chunks = upsert_text(doc_id, text)
    return {
        "filename": doc_id,
        "chunks": n_chunks,
        "chars": len(text)
    }

@app.post("/chat")
async def chat(question: str):
    """
    Returns an answer generated by Llama-3 using retrieval-augmented context.
    """
    return {"answer": answer(question)}


@app.post("/chat/stream")
async def chat_stream(question: str):
    """
    Streams tokens as Server-Sent Events. Each SSE data field contains
    a token chunk; the client concatenates them.
    """

    async def event_generator():
        for token in stream_answer(question):
            yield {"data": token}
        yield {"event": "done", "data": ""}

    return EventSourceResponse(event_generator())